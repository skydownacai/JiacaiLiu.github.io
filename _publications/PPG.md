---
title: "Projected Policy Gradient Converges in a Finite Number of Iterations"
collection: publications
permalink: /publication/PPG
excerpt: ''
date: 2023-11-02
venue: 'arxiv'
paperurl: 'https://arxiv.org/abs/2311.01104'
citation: ' Jiacai Liu, Wenye Li, and Ke Wei. Projected Policy Gradient Converges in a Finite Number of Iterations. arXiv:2311.0110, 2023.'
---

The convergence of the projected policy gradient (PPG) method under the simplex parameterization is studied and it is shown that this method indeed achieves the exact convergence in a finite number of iterations for any constant step size. To establish this result, we first establish the sublinear convergence of PPG for an arbitrary fixed step size, which is also new, to the best of knowledge. The finite iteration convergence property is also applicable to a preconditioned version of PPG, namely the projected Q-ascent (PQA) method. Additionally, the linear convergence of PPG and its equivalence to PI are established under the non-adaptive increasing step sizes and the adaptive step sizes, respectively.